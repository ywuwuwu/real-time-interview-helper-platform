#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºçš„Planner AIåŠŸèƒ½
"""

import asyncio
import json
from services.planner_analysis import PlannerAnalysisService
from config import config

async def test_enhanced_planner():
    """æµ‹è¯•å¢å¼ºçš„PlanneråŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•å¢å¼ºçš„Planner AIåŠŸèƒ½...")
    
    # åˆå§‹åŒ–æœåŠ¡
    planner_service = PlannerAnalysisService(config.OPENAI_API_KEY)
    
    # æµ‹è¯•æ•°æ®
    job_description = """
    æˆ‘ä»¬æ­£åœ¨å¯»æ‰¾ä¸€ä½ç»éªŒä¸°å¯Œçš„å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£å¼€å‘å’Œç»´æŠ¤æˆ‘ä»¬çš„Webåº”ç”¨ç¨‹åºã€‚
    
    èŒä½è¦æ±‚ï¼š
    - 3å¹´ä»¥ä¸ŠPythonå¼€å‘ç»éªŒ
    - ç†Ÿç»ƒæŒæ¡React.jså’Œç°ä»£å‰ç«¯æŠ€æœ¯
    - æœ‰Dockerå’ŒAWSä½¿ç”¨ç»éªŒ
    - ç†Ÿæ‚‰æ•°æ®åº“è®¾è®¡å’Œç®¡ç†ï¼ˆMySQL/PostgreSQLï¼‰
    - å…·å¤‡è‰¯å¥½çš„å›¢é˜Ÿåä½œå’Œæ²Ÿé€šèƒ½åŠ›
    - æœ‰å¾®æœåŠ¡æ¶æ„ç»éªŒä¼˜å…ˆ
    
    èŒè´£ï¼š
    - è®¾è®¡å’Œå¼€å‘æ–°çš„åŠŸèƒ½æ¨¡å—
    - ä¼˜åŒ–ç°æœ‰ç³»ç»Ÿæ€§èƒ½
    - å‚ä¸ä»£ç å®¡æŸ¥å’ŒæŠ€æœ¯è®¨è®º
    - ä¸äº§å“å›¢é˜Ÿåä½œï¼Œç†è§£éœ€æ±‚å¹¶å®ç°
    """
    
    user_skills = ["Python", "JavaScript", "React", "Git", "MySQL", "Docker"]
    experience_years = 2
    
    print(f"\nğŸ“ èŒä½æè¿°: {job_description[:100]}...")
    print(f"ğŸ‘¤ ç”¨æˆ·æŠ€èƒ½: {', '.join(user_skills)}")
    print(f"â° å·¥ä½œç»éªŒ: {experience_years}å¹´")
    
    try:
        # æµ‹è¯•æŠ€èƒ½æå–
        print("\nğŸ” æµ‹è¯•æŠ€èƒ½æå–...")
        jd_skills = planner_service.extract_skills_from_jd(job_description)
        print(f"âœ… æå–åˆ° {len(jd_skills.get('required_skills', []))} ä¸ªå¿…éœ€æŠ€èƒ½")
        print(f"ğŸ“‹ æŠ€èƒ½åˆ—è¡¨: {[skill['skill'] for skill in jd_skills.get('required_skills', [])]}")
        
        # æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼åº¦
        print("\nğŸ¯ æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼åº¦...")
        similarity = planner_service.calculate_semantic_similarity("Python", "Python")
        print(f"âœ… Python vs Python ç›¸ä¼¼åº¦: {similarity:.3f}")
        
        similarity = planner_service.calculate_semantic_similarity("React", "Vue")
        print(f"âœ… React vs Vue ç›¸ä¼¼åº¦: {similarity:.3f}")
        
        # æµ‹è¯•æŠ€èƒ½å·®è·åˆ†æ
        print("\nğŸ“Š æµ‹è¯•æŠ€èƒ½å·®è·åˆ†æ...")
        skill_gaps = planner_service.analyze_skill_gaps(
            jd_skills.get("required_skills", []), 
            user_skills
        )
        print(f"âœ… å·®è·æ•°é‡: {skill_gaps['gap_count']}")
        print(f"âœ… ä¼˜åŠ¿æ•°é‡: {skill_gaps['strength_count']}")
        
        # æµ‹è¯•å®Œæ•´çš„èŒä½åŒ¹é…åˆ†æ
        print("\nğŸ¯ æµ‹è¯•å®Œæ•´çš„èŒä½åŒ¹é…åˆ†æ...")
        analysis_result = await planner_service.analyze_job_match(
            job_description, user_skills, experience_years
        )
        
        print(f"âœ… æŠ€èƒ½åŒ¹é…åº¦: {analysis_result['skill_match']}%")
        print(f"âœ… ç»éªŒåŒ¹é…åº¦: {analysis_result['experience_match']}%")
        print(f"âœ… æ•´ä½“åŒ¹é…åº¦: {analysis_result['overall_match']}%")
        print(f"âœ… ç½®ä¿¡åº¦åˆ†æ•°: {analysis_result['confidence_score']}%")
        
        # æ˜¾ç¤ºè¯¦ç»†åˆ†æ
        print("\nğŸ“‹ è¯¦ç»†åˆ†æç»“æœ:")
        detailed = analysis_result.get('detailed_analysis', {})
        print(f"  æ ¸å¿ƒç«äº‰åŠ›: {', '.join(detailed.get('core_competencies', []))}")
        print(f"  ä¸»è¦å·®è·: {', '.join(detailed.get('main_gaps', []))}")
        print(f"  çŸ­æœŸç›®æ ‡: {', '.join(detailed.get('short_term_goals', []))}")
        
        # æ˜¾ç¤ºæ”¹è¿›ä¼˜å…ˆçº§
        print("\nğŸ¯ æ”¹è¿›ä¼˜å…ˆçº§:")
        priorities = analysis_result.get('improvement_priorities', [])
        for i, priority in enumerate(priorities[:3], 1):
            print(f"  {i}. {priority['skill']} (ä¼˜å…ˆçº§: {priority['priority_score']}, é¢„è®¡æ—¶é—´: {priority['estimated_time']})")
        
        # æ˜¾ç¤ºæ—¶é—´çº¿ä¼°ç®—
        print("\nâ° æ”¹è¿›æ—¶é—´çº¿:")
        timeline = analysis_result.get('timeline_estimate', {})
        print(f"  æ€»å‘¨æ•°: {timeline.get('total_weeks', 0)}å‘¨")
        print(f"  é¢„è®¡å®Œæˆæ—¥æœŸ: {timeline.get('estimated_completion_date', 'N/A')}")
        
        # ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
        with open('enhanced_planner_test_result.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° enhanced_planner_test_result.json")
        
        print("\nğŸ‰ å¢å¼ºçš„Planner AIåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def test_semantic_matching():
    """æµ‹è¯•è¯­ä¹‰åŒ¹é…åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•è¯­ä¹‰åŒ¹é…åŠŸèƒ½...")
    
    planner_service = PlannerAnalysisService(config.OPENAI_API_KEY)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("Python", "Python"),
        ("React", "Vue"),
        ("JavaScript", "TypeScript"),
        ("Docker", "Kubernetes"),
        ("MySQL", "PostgreSQL"),
        ("AWS", "Azure"),
        ("é¡¹ç›®ç®¡ç†", "å›¢é˜Ÿåä½œ"),
        ("æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ")
    ]
    
    print("ğŸ“Š è¯­ä¹‰ç›¸ä¼¼åº¦æµ‹è¯•ç»“æœ:")
    for skill1, skill2 in test_cases:
        similarity = planner_service.calculate_semantic_similarity(skill1, skill2)
        print(f"  {skill1} vs {skill2}: {similarity:.3f}")
    
    print("\nâœ… è¯­ä¹‰åŒ¹é…æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª å¢å¼ºçš„Planner AIåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_enhanced_planner())
    asyncio.run(test_semantic_matching())
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 60) 