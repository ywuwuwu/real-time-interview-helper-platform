#!/usr/bin/env python3
"""
æµ‹è¯•PDFè§£æä¿®å¤
"""

import asyncio
import json
import os
from services.planner_analysis import PlannerAnalysisService
from config import config

async def test_pdf_fix():
    """æµ‹è¯•PDFè§£æä¿®å¤"""
    print("ğŸš€ æµ‹è¯•PDFè§£æä¿®å¤...")
    
    # åˆ›å»ºæµ‹è¯•ç®€å†å†…å®¹ï¼ˆæ¨¡æ‹ŸPDFå†…å®¹ï¼‰
    test_resume_content = """Position: Software Engineer, Machine Learning â€“ Off-Search Sourcing and Relevance
Professional Summary
- 4+ years of full SDLC experience: software development, design, implementation, testing, and operations
- Expert in software development best practices: coding standards, code reviews, and source control management
- Proven ability in system design and architecture for high-concurrency, distributed systems
- Skilled in machine learning: data pipelines, feature engineering, model training, A/B testing, and deployment
- Experienced in DevOps and operations: CI/CD, monitoring, troubleshooting, and production support

Core Skills
- Software Development
- Machine Learning
- Data Pipelines
- Distributed Systems
- System Design
- Programming Languages
- A/B Testing
- Statistics
- Information Retrieval

Professional Experience
Senior Software Engineer | ABC Tech Co., Ltd.
July 2022 â€“ Present, Beijing
- Led end-to-end software development, from architecture design through testing and operations
- Established and enforced coding standards and code review processes, improving code quality by 30%
- Managed Git-based source control workflows with branching strategies and pull request best practices
- Architected a distributed system for low-latency ad serving handling 100M+ QPS with fault tolerance
- Built real-time data pipelines (Kafka â†’ Spark Streaming â†’ HBase) for feature extraction and model inputs
- Developed and deployed ML models in TensorFlow; performed A/B testing to validate improvements
- Oversaw system monitoring and production incident management, ensuring 99.9% uptime

Software Engineer | DEF Information Technology Ltd.
June 2019 â€“ June 2022, Shanghai
- Designed and implemented an offline ETL pipeline processing hundreds of billions of records using Spark and Hadoop
- Automated testing workflows with pytest and Jenkins; reduced manual QA time by 50%
- Participated in system design reviews to improve scalability and reliability
- Collaborated on code reviews and maintained high code quality standards
- Managed production operations and optimized CI/CD pipelines

Selected Projects
Off-Search Ad Relevance Engine
- Role: Lead Architect & Developer
- Tech & Practices: microservices, gRPC, Kafka, TensorFlow, automated testing, Kubernetes
- Impact: 6% uplift in off-search CTR, 8% incremental revenue

Real-Time CTR Prediction Pipeline
- Role: Full-Stack Engineer
- Tech & Practices: real-time streaming, pipeline orchestration, CI/CD, monitoring, A/B testing
- Impact: Maintained <50ms p99 latency with 24/7 stability

Education
Bachelor of Science in Computer Science | Peking University
September 2015 â€“ June 2019

Certifications & Honors
- AWS Certified Solutions Architect â€“ Associate
- TensorFlow Developer Certificate
- Engineer of the Year â€“ ABC Tech Co., Ltd. (2023)

Open Source & Community
- GitHub: https://github.com/your-username
- Contributions: Spark plugins, Feature Store reference implementation"""
    
    # ä¿å­˜æµ‹è¯•ç®€å†æ–‡ä»¶ï¼ˆæ–‡æœ¬æ ¼å¼ï¼Œæ¨¡æ‹ŸPDFå†…å®¹ï¼‰
    test_resume_path = "test_resume_full_skills.txt"
    with open(test_resume_path, 'w', encoding='utf-8') as f:
        f.write(test_resume_content)
    
    try:
        # åˆå§‹åŒ–æœåŠ¡
        planner_service = PlannerAnalysisService(config.OPENAI_API_KEY)
        
        # æµ‹è¯•ç®€å†è§£æ
        print("\nğŸ“„ æµ‹è¯•ç®€å†è§£æ...")
        resume_data = await planner_service.parse_resume(test_resume_path)
        
        print(f"\nâœ… ç®€å†è§£æç»“æœ:")
        print(f"  - æŠ€èƒ½: {resume_data['skills']}")
        print(f"  - å·¥ä½œç»éªŒ: {resume_data['experience_years']} å¹´")
        print(f"  - å­¦å†: {resume_data['education']}")
        print(f"  - é¡¹ç›®: {resume_data['projects']}")
        print(f"  - è¯­è¨€: {resume_data['languages']}")
        print(f"  - è®¤è¯: {resume_data['certifications']}")
        
        # æµ‹è¯•æŠ€èƒ½åŒ¹é…åˆ†æ
        print("\nğŸ¯ æµ‹è¯•æŠ€èƒ½åŒ¹é…åˆ†æ...")
        jd_description = """
        æˆ‘ä»¬æ­£åœ¨å¯»æ‰¾ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°æ®ç§‘å­¦å®¶ï¼Œè´Ÿè´£å¼€å‘å’Œç»´æŠ¤æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚
        
        èŒä½è¦æ±‚ï¼š
        - 3å¹´ä»¥ä¸ŠPythonå¼€å‘ç»éªŒ
        - ç†Ÿç»ƒæŒæ¡æœºå™¨å­¦ä¹ ç®—æ³•å’Œç»Ÿè®¡æ–¹æ³•
        - æœ‰åˆ†å¸ƒå¼ç³»ç»Ÿå’Œå¤§æ•°æ®å¤„ç†ç»éªŒ
        - ç†Ÿæ‚‰A/Bæµ‹è¯•å’Œå®éªŒè®¾è®¡
        - å…·å¤‡è‰¯å¥½çš„ç¼–ç¨‹è§„èŒƒå’Œè®¾è®¡æ¨¡å¼
        - æœ‰è‡ªç„¶è¯­è¨€å¤„ç†ç»éªŒä¼˜å…ˆ
        
        èŒè´£ï¼š
        - è®¾è®¡å’Œå¼€å‘æœºå™¨å­¦ä¹ æ¨¡å‹
        - è¿›è¡Œæ•°æ®åˆ†æå’Œç»Ÿè®¡å»ºæ¨¡
        - å‚ä¸ä»£ç å®¡æŸ¥å’ŒæŠ€æœ¯è®¨è®º
        - ä¸äº§å“å›¢é˜Ÿåä½œï¼Œç†è§£éœ€æ±‚å¹¶å®ç°
        """
        
        analysis_result = await planner_service.analyze_job_match(
            jd_description,
            resume_data['skills'],
            resume_data['experience_years']
        )
        
        print(f"\nğŸ“Š åŒ¹é…åº¦åˆ†æç»“æœ:")
        print(f"  - æŠ€èƒ½åŒ¹é…åº¦: {analysis_result['skill_match']}%")
        print(f"  - ç»éªŒåŒ¹é…åº¦: {analysis_result['experience_match']}%")
        print(f"  - æ•´ä½“åŒ¹é…åº¦: {analysis_result['overall_match']}%")
        print(f"  - å·®è·æ•°é‡: {len(analysis_result['gaps'])}")
        print(f"  - ä¼˜åŠ¿æ•°é‡: {len(analysis_result['strengths'])}")
        
        # æ˜¾ç¤ºå·®è·è¯¦æƒ…
        if analysis_result['gaps']:
            print("\nğŸ“‹ æŠ€èƒ½å·®è·è¯¦æƒ…:")
            for gap in analysis_result['gaps']:
                status_icon = "âŒ" if gap['status'] == 'missing' else "âš ï¸"
                print(f"  {status_icon} {gap['skill']} ({gap['priority']} priority)")
        
        # æ˜¾ç¤ºä¼˜åŠ¿è¯¦æƒ…
        if analysis_result['strengths']:
            print("\nâœ… æŠ€èƒ½ä¼˜åŠ¿è¯¦æƒ…:")
            for strength in analysis_result['strengths']:
                print(f"  âœ… {strength['skill']} (é‡è¦æ€§: {strength['importance']})")
        
        # è¯¦ç»†æŠ€èƒ½åˆ†æ
        user_skills = set(skill.lower() for skill in resume_data['skills'])
        matched_skills = set(strength['skill'].lower() for strength in analysis_result.get('strengths', []))
        gap_skills = set(gap['skill'].lower() for gap in analysis_result.get('gaps', []))
        extra_skills = user_skills - matched_skills - gap_skills
        
        print(f"\nğŸ” è¯¦ç»†æŠ€èƒ½åˆ†æ:")
        print(f"  - ç”¨æˆ·æŠ€èƒ½æ€»æ•°: {len(resume_data['skills'])}")
        print(f"  - åŒ¹é…æŠ€èƒ½: {len(analysis_result.get('strengths', []))} é¡¹")
        print(f"  - ç¼ºå¤±æŠ€èƒ½: {len(analysis_result.get('gaps', []))} é¡¹")
        print(f"  - é¢å¤–æŠ€èƒ½: {len(extra_skills)} é¡¹")
        
        # æ˜¾ç¤ºåŒ¹é…çš„æŠ€èƒ½
        if analysis_result.get('strengths'):
            print(f"\nâœ… åŒ¹é…çš„æŠ€èƒ½:")
            for strength in analysis_result['strengths']:
                print(f"    - {strength['skill']} (é‡è¦æ€§: {strength['importance']})")
        
        # æ˜¾ç¤ºç¼ºå¤±çš„æŠ€èƒ½
        if analysis_result.get('gaps'):
            print(f"\nâŒ ç¼ºå¤±çš„æŠ€èƒ½:")
            for gap in analysis_result['gaps']:
                status_icon = "âŒ" if gap['status'] == 'missing' else "âš ï¸"
                print(f"    {status_icon} {gap['skill']} ({gap['priority']} priority)")
                if gap.get('similar_skill'):
                    print(f"      ç›¸å…³æŠ€èƒ½: {gap['similar_skill']}")
        
        # æ˜¾ç¤ºå²—ä½æ²¡æœ‰è¦æ±‚çš„æŠ€èƒ½
        if extra_skills:
            print(f"\nğŸ’¡ å²—ä½æ²¡æœ‰è¦æ±‚çš„æŠ€èƒ½:")
            for skill in extra_skills:
                print(f"    - {skill}")
        
        print(f"\nğŸ“‹ æŠ€èƒ½åŒ¹é…æ€»ç»“:")
        print(f"  - åŒ¹é…ç‡: {len(analysis_result.get('strengths', []))}/{len(resume_data['skills'])} = {analysis_result['skill_match']:.1f}%")
        print(f"  - ä¼˜åŠ¿æŠ€èƒ½: {len(analysis_result.get('strengths', []))} é¡¹")
        print(f"  - éœ€è¦æå‡: {len(analysis_result.get('gaps', []))} é¡¹")
        print(f"  - é¢å¤–æŠ€èƒ½: {len(extra_skills)} é¡¹")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        test_result = {
            "resume_content": test_resume_content,
            "parsed_resume": resume_data,
            "analysis_result": analysis_result,
            "detailed_analysis": {
                "user_skills": list(user_skills),
                "matched_skills": list(matched_skills),
                "gap_skills": list(gap_skills),
                "extra_skills": list(extra_skills),
                "skill_summary": {
                    "total_user_skills": len(resume_data['skills']),
                    "matched_count": len(analysis_result.get('strengths', [])),
                    "missing_count": len(analysis_result.get('gaps', [])),
                    "extra_count": len(extra_skills),
                    "match_rate": analysis_result['skill_match']
                }
            }
        }
        
        with open('pdf_fix_test_result.json', 'w', encoding='utf-8') as f:
            json.dump(test_result, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° pdf_fix_test_result.json")
        print("\nğŸ‰ PDFè§£æä¿®å¤æµ‹è¯•æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_resume_path):
            os.remove(test_resume_path)

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§ª PDFè§£æä¿®å¤æµ‹è¯•")
    print("=" * 60)
    
    asyncio.run(test_pdf_fix())
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 60) 